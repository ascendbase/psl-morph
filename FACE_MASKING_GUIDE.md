# üé≠ Face Masking Implementation Guide

Instead of using ReActor face swapping, you can use face detection and masking to paste only the generated face area onto the original image. This gives you more control and better results.

## üéØ **What You Want to Achieve**

1. **Load original image**
2. **Generate new face** with your LoRA
3. **Detect face area** in original image
4. **Create mask** around the face
5. **Paste generated face** only in the masked area
6. **Blend edges** for seamless result

## üîß **Available Workflow Options**

I've created 3 different workflow approaches for you to try:

### **Option 1: Face Inpainting** [`workflow_inpaint_face.json`](comfyui_workflows/workflow_inpaint_face.json)
- Uses **SAM (Segment Anything Model)** for face detection
- **Inpaints only the face area** with your LoRA
- **Most seamless blending**
- Requires: SAM extension

### **Option 2: Face Detection + Composite** [`workflow_face_mask.json`](comfyui_workflows/workflow_face_mask.json)
- Uses **FaceDetailer** for precise face detection
- **Generates full image** then composites face area
- **Good control over face boundaries**
- Requires: Face Tools extension

### **Option 3: Advanced Masking** [`workflow_mask_composite.json`](comfyui_workflows/workflow_mask_composite.json)
- Uses **UltralyticsDetectorProvider** for detection
- **Advanced mask processing** with blur
- **Professional compositing**
- Requires: Impact Pack extension

## üì¶ **Required Extensions**

Depending on which workflow you choose, you'll need:

### **For Face Inpainting (Recommended)**
```bash
cd ComfyUI/custom_nodes
git clone https://github.com/storyicon/comfyui_segment_anything.git
cd comfyui_segment_anything
pip install -r requirements.txt
```

### **For Face Tools**
```bash
cd ComfyUI/custom_nodes
git clone https://github.com/cubiq/ComfyUI_FaceAnalysis.git
cd ComfyUI_FaceAnalysis
pip install -r requirements.txt
```

### **For Advanced Detection**
```bash
cd ComfyUI/custom_nodes
git clone https://github.com/ltdrdata/ComfyUI-Impact-Pack.git
cd ComfyUI-Impact-Pack
pip install -r requirements.txt
```

## üöÄ **Quick Setup Steps**

### **Step 1: Choose Your Approach**
Pick one of the 3 workflows based on what extensions you have or want to install.

### **Step 2: Install Required Extension**
Follow the installation commands above for your chosen approach.

### **Step 3: Update App Configuration**
I can update the app to use your preferred workflow instead of the ReActor one.

### **Step 4: Test in ComfyUI**
1. Open ComfyUI web interface
2. Load your chosen workflow JSON
3. Upload a test image
4. Run manually to verify it works
5. Check that face detection and masking work properly

## üé® **How Each Approach Works**

### **Face Inpainting Workflow**
```
Original Image ‚Üí Face Detection ‚Üí Create Mask ‚Üí Inpaint Face Area ‚Üí Result
```
- **Pros**: Most seamless, natural blending
- **Cons**: Requires SAM model download (~2GB)

### **Face Detection + Composite**
```
Original Image ‚Üí Generate Full Image ‚Üí Detect Face ‚Üí Composite Face Area ‚Üí Result
```
- **Pros**: More control, works with existing extensions
- **Cons**: May need edge blending adjustment

### **Advanced Masking**
```
Original Image ‚Üí Generate Full Image ‚Üí Advanced Detection ‚Üí Blur Mask ‚Üí Composite ‚Üí Result
```
- **Pros**: Professional results, fine control
- **Cons**: More complex setup

## ‚öôÔ∏è **Workflow Customization**

Each workflow can be customized:

### **Face Detection Settings**
- **Padding**: How much area around face to include
- **Blur**: Edge softening for seamless blending
- **Threshold**: Face detection sensitivity

### **Generation Settings**
- **Denoise**: Your HTN/Chadlite/Chad presets (20%/50%/80%)
- **Steps**: Generation quality (20 steps default)
- **CFG**: Prompt adherence (8.0 default)

## üîÑ **Switching from ReActor**

To switch from ReActor to face masking:

1. **Choose workflow** (I recommend Face Inpainting)
2. **Install required extension**
3. **Test workflow** in ComfyUI manually
4. **Update app configuration** to use new workflow
5. **Test web app** with all three presets

## üéØ **Expected Results**

With face masking instead of ReActor:
- **Better edge blending** around face area
- **More natural integration** with original image
- **Preserved background** and hair details
- **Controlled transformation** area
- **No face swap artifacts**

## üõ†Ô∏è **Troubleshooting**

### **Face Not Detected**
- Adjust detection threshold
- Ensure face is clearly visible
- Try different detection model

### **Harsh Edges**
- Increase mask blur radius
- Add more padding around face
- Use feathering on mask edges

### **Poor Blending**
- Adjust composite opacity
- Use gradient masks
- Fine-tune mask boundaries

## üìû **Next Steps**

Which workflow approach would you like to try?

1. **Face Inpainting** (recommended for best results)
2. **Face Detection + Composite** (if you have Face Tools)
3. **Advanced Masking** (if you have Impact Pack)

Once you choose, I'll:
1. **Update the app** to use your preferred workflow
2. **Add configuration options** for face detection settings
3. **Test the integration** with your HTN/Chadlite/Chad presets
4. **Provide setup instructions** for the required extensions

---

**The face masking approach will give you much better control and more natural results than ReActor face swapping!**